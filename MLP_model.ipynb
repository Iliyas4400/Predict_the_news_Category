{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-ZV-AnOEa9KE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J8o87Nd_JWk_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hpZDOPJJtuJ",
    "outputId": "815cbd31-4061-47ac-f6b2-a54eb2e357ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer,LancasterStemmer\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8BIkHrgUwLux"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "MUWomcfca9KN",
    "outputId": "3e35b75d-9e1a-4aae-ee7e-9df30281a34c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the most painful was the huge reversal in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How formidable is the opposition alliance amon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most Asian currencies were trading lower today...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you want to answer any question, click on ‘...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In global markets, gold prices edged up today ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY  SECTION\n",
       "0  But the most painful was the huge reversal in ...        3\n",
       "1  How formidable is the opposition alliance amon...        0\n",
       "2  Most Asian currencies were trading lower today...        3\n",
       "3  If you want to answer any question, click on ‘...        1\n",
       "4  In global markets, gold prices edged up today ...        3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Data_Train.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2Mdtx35a9KO",
    "outputId": "b0c6786a-8d4a-4800-f350-be1cbf1499ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2772\n",
       "2    1924\n",
       "0    1686\n",
       "3    1246\n",
       "Name: SECTION, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SECTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2731\n",
       "2    1914\n",
       "0    1673\n",
       "3    1233\n",
       "Name: SECTION, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates()\n",
    "df['SECTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "pi0UGLHKa9KP",
    "outputId": "fd676f32-66d9-4e1c-a7eb-5b9f149de670"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But the most painful was the huge reversal in fee income, unheard of among private sector lenders. Essentially, it means that Yes Bank took it for granted that fees on structured loan deals will be paid and accounted for upfront on its books. As borrowers turned defaulters, the fees tied to these loan deals fell off the cracks. Gill has now vowed to shift to a safer accounting practice of amortizing fee income rather than booking these upfront.\\n\\n\\nGill’s move to mend past ways means that there will be no nasty surprises in the future. This is good news considering that investors love a clean image and loathe uncertainties.\\n\\n\\nBut there is no gain without pain and the promise of a strong and stable balance sheet comes with some sacrifices as well. Investors will have to give up the hopes of phenomenal growth, a promise made by Kapoor.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "gcxJz55Ma9KP",
    "outputId": "45a8cf4a-61a7-47ea-d51e-52f1e9946e57",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“One would think that their development and testing process would’ve uncovered many of these flaws, and yet they proceeded to put it in the market anyway,\" said Bryan Ma, vice president of devices research at consultancy IDC. “Clearly they can’t afford to have another embarrassing Note 7-like incident, lest they build up a reputation for releasing unreliable products.\"\\n\\n\\nThe Note 7 episode triggered a global recall, cost the company billions of dollars and marred its reputation as it battled Apple Inc. in premium devices. Pulling the Fold now lets the Korean giant address potential issues as it races to put out a flexible gadget ahead of Chinese rival Huawei Technologies Co. and Xiaomi Corp.\\n\\n\\nA Samsung spokeswoman declined to comment for this story. Shares in the company, which hasn’t set another date for a commercial launch, were little changed in Seoul on Wednesday.\\n\\n\\nSamsung has bounced back since the Note 7 — it remains the world’s largest producer of smartphones and memory chips. But it was counting on the folding devices to extend its lead in mobile and kick-start a stagnating global market.\\n\\n\\nUnveiled along with the 10th-anniversary version of the flagship Galaxy S phone, the Fold underscored Samsung’s ambitions like no other product it makes. Struggling to ward off hard-charging rivals, the Suwon, South Korea-based giant hoped the gadget would embody its lead in cutting-edge innovation.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['STORY'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "5qrydzBopXoX",
    "outputId": "8d0af6f6-8431-4a64-9661-5f50f8cc4f1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019 will see gadgets like gaming smartphones ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It has also unleashed a wave of changes in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It can be confusing to pick the right smartpho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mobile application is integrated with a da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have rounded up some of the gadgets that sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               STORY\n",
       "0  2019 will see gadgets like gaming smartphones ...\n",
       "1  It has also unleashed a wave of changes in the...\n",
       "2  It can be confusing to pick the right smartpho...\n",
       "3  The mobile application is integrated with a da...\n",
       "4  We have rounded up some of the gadgets that sh..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te=pd.read_excel('Data_Test.xlsx')\n",
    "df_te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain','aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "   \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "def preprocess_text(sentance):\n",
    "    sent = decontracted(sentance)\n",
    "\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace(',', '')\n",
    "    sent = re.sub('\\sCo\\.',' company',sent)\n",
    "    sent = re.sub('\\sCorp\\.',' corporation',sent)\n",
    "    sent = re.sub('&','and',sent)\n",
    "\n",
    "    sent = re.sub('\\$',' dollars ',sent)\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "\n",
    "    sent = ' '.join(lemmatizer.lemmatize(e.lower()) for e in sent.split() if e.lower() not in stopwords and len(e)>1)\n",
    "    #sent = ' '.join(e.lower() for e in sent.split())\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_(df,c):\n",
    "    text=[]  \n",
    "    for i in tqdm(range(len(df['STORY']))):\n",
    "        try:\n",
    "            if df['SECTION'][i]==c:\n",
    "                text.append(preprocess_text(df['STORY'][i]))      \n",
    "        except KeyError:\n",
    "            continue\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7551/7551 [00:01<00:00, 3994.71it/s]\n",
      "100%|██████████| 7551/7551 [00:02<00:00, 3002.47it/s]\n",
      "100%|██████████| 7551/7551 [00:00<00:00, 7751.31it/s]\n",
      "100%|██████████| 7551/7551 [00:01<00:00, 7203.05it/s]\n"
     ]
    }
   ],
   "source": [
    "X0=preprocess_(df,0)\n",
    "X1=preprocess_(df,1)\n",
    "X2=preprocess_(df,2)\n",
    "X3=preprocess_(df,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(X):\n",
    "    w=[]\n",
    "    for i in X:\n",
    "        w.extend(i.split())\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0=words(X0)\n",
    "w1=words(X1)\n",
    "w2=words(X2)\n",
    "w3=words(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist_w0 = FreqDist(w0)\n",
    "freq_dist_w1 = FreqDist(w1)\n",
    "freq_dist_w2 = FreqDist(w2)\n",
    "freq_dist_w3 = FreqDist(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('party', 2001), ('bjp', 1904), ('congress', 1735), ('election', 1592), ('not', 1390), ('said', 1316), ('seat', 1133), ('state', 1119), ('modi', 949), ('minister', 900), ('sabha', 794), ('lok', 793), ('government', 705), ('also', 696), ('leader', 679), ('people', 636), ('india', 632), ('poll', 611), ('political', 583), ('year', 575), ('chief', 524), ('candidate', 524), ('gandhi', 512), ('vote', 508), ('one', 496), ('constituency', 492), ('alliance', 489), ('two', 487), ('time', 466), ('2014', 450), ('phase', 416), ('national', 403), ('delhi', 401), ('pradesh', 399), ('voter', 398), ('new', 380), ('prime', 379), ('issue', 365), ('last', 354), ('janata', 349), ('would', 348), ('assembly', 334), ('first', 331), ('president', 324), ('no', 316), ('country', 306), ('former', 306), ('campaign', 303), ('may', 299), ('narendra', 294)]\n"
     ]
    }
   ],
   "source": [
    "n=50\n",
    "print(freq_dist_w0.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('not', 1313), ('user', 1224), ('also', 1185), ('new', 1183), ('company', 1146), ('said', 1135), ('india', 1128), ('apple', 991), ('phone', 940), ('year', 927), ('smartphone', 914), ('camera', 798), ('device', 795), ('data', 757), ('like', 736), ('google', 717), ('one', 715), ('feature', 688), ('samsung', 675), ('app', 657), ('pro', 643), ('facebook', 614), ('technology', 589), ('market', 572), ('display', 565), ('time', 564), ('would', 534), ('service', 529), ('come', 524), ('galaxy', 500), ('first', 498), ('iphone', 477), ('people', 476), ('million', 456), ('dollar', 450), ('note', 444), ('screen', 439), ('u', 438), ('sale', 435), ('two', 435), ('smartphones', 434), ('huawei', 430), ('according', 425), ('make', 413), ('whatsapp', 396), ('price', 394), ('last', 392), ('platform', 392), ('available', 391), ('use', 385)]\n"
     ]
    }
   ],
   "source": [
    "print(freq_dist_w1.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('film', 1027), ('not', 663), ('also', 433), ('actor', 424), ('said', 386), ('like', 337), ('movie', 335), ('one', 315), ('year', 303), ('time', 286), ('avenger', 273), ('show', 260), ('character', 257), ('would', 242), ('first', 232), ('star', 224), ('endgame', 220), ('story', 209), ('people', 195), ('day', 189), ('director', 183), ('life', 175), ('say', 171), ('man', 164), ('two', 161), ('fan', 158), ('marvel', 157), ('set', 155), ('release', 150), ('new', 149), ('love', 149), ('world', 145), ('make', 143), ('even', 142), ('role', 141), ('work', 135), ('get', 128), ('series', 127), ('back', 126), ('made', 126), ('last', 126), ('way', 125), ('wrote', 123), ('screen', 121), ('know', 120), ('thing', 120), ('audience', 119), ('seen', 119), ('season', 117), ('come', 114)]\n"
     ]
    }
   ],
   "source": [
    "print(freq_dist_w2.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dollar', 935), ('year', 869), ('said', 802), ('market', 730), ('price', 510), ('company', 458), ('bank', 428), ('india', 419), ('u', 404), ('crore', 384), ('investor', 383), ('growth', 373), ('stock', 363), ('share', 363), ('ltd', 357), ('not', 351), ('month', 329), ('also', 296), ('quarter', 290), ('index', 272), ('currency', 263), ('last', 258), ('oil', 255), ('global', 242), ('march', 242), ('trading', 240), ('trade', 240), ('analyst', 239), ('per', 237), ('rupee', 237), ('new', 237), ('10', 236), ('percent', 230), ('rate', 228), ('point', 228), ('equity', 225), ('china', 224), ('may', 216), ('bond', 215), ('time', 214), ('gold', 213), ('two', 213), ('since', 211), ('indian', 209), ('data', 206), ('week', 201), ('higher', 198), ('high', 196), ('billion', 186), ('yield', 185)]\n"
     ]
    }
   ],
   "source": [
    "print(freq_dist_w3.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "s0=[]\n",
    "for i in freq_dist_w0.most_common(n):\n",
    "    s0.append(i[0])\n",
    "s1=[]\n",
    "for i in freq_dist_w1.most_common(n):\n",
    "    s1.append(i[0])\n",
    "s2=[]\n",
    "for i in freq_dist_w2.most_common(n):\n",
    "    s2.append(i[0])\n",
    "s3=[]\n",
    "for i in freq_dist_w3.most_common(n):\n",
    "    s3.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n",
      "also\n",
      "new\n",
      "company\n",
      "said\n",
      "india\n",
      "year\n",
      "data\n",
      "market\n",
      "time\n",
      "dollar\n",
      "u\n",
      "two\n",
      "price\n",
      "last\n"
     ]
    }
   ],
   "source": [
    "c=[]\n",
    "for i in s1:\n",
    "    if i in s3:\n",
    "        c.append(i)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not\n",
      "said\n",
      "also\n",
      "people\n",
      "year\n",
      "one\n",
      "two\n",
      "time\n",
      "new\n",
      "last\n",
      "would\n",
      "first\n"
     ]
    }
   ],
   "source": [
    "c=[]\n",
    "for i in s0:\n",
    "    if i in s2:\n",
    "        c.append(i)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add words that are common\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we','not','said','our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain','aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\", 'also','new','year','one','two','would','may','india']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train(df):\n",
    "    text=[];label=[];story=[]\n",
    "    for i in tqdm(range(len(df['SECTION']))):\n",
    "        try:\n",
    "            l=re.findall(r'This story has been published from a wire agency feed without modifications to the text. Only the headline has been changed',df['STORY'][i])\n",
    "            if len(l)!=0 :\n",
    "                s=df['STORY'][i]\n",
    "                phrase = re.sub(r\"This story has been published from a wire agency feed without modifications to the text. Only the headline has been changed\", \"\",s)\n",
    "                if len(phrase)>10:\n",
    "                    story.append(df['STORY'][i])\n",
    "                    text.append(preprocess_text(phrase))\n",
    "                    label.append(df['SECTION'][i])\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                story.append(df['STORY'][i])\n",
    "                text.append(preprocess_text(df['STORY'][i]))\n",
    "                label.append(df['SECTION'][i])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return text,label,story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7551/7551 [00:09<00:00, 794.10it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7469, 7469, 7469)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p,label_tr,X=preprocess_train(df)\n",
    "y=np.array(label_tr)\n",
    "len(X_p),len(y),len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df):\n",
    "    text=[]  \n",
    "    for i in tqdm(range(len(df['STORY']))):\n",
    "         text.append(preprocess_text(df['STORY'][i]))      \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2748/2748 [00:02<00:00, 1228.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2748"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_te=preprocess_test(df_te)\n",
    "len(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8n6CCAUCfik",
    "outputId": "1c326f38-e8bf-4dfb-88e9-324878156a6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(X_p)\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "# dictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
    "# tfidf_words_essay = set(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7469, 30188)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_tfidf=tfidf_model.transform(X_p)\n",
    "X_tr_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 30188)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_te_tfidf=tfidf_model.transform(X_te)\n",
    "X_te_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=64, early_stopping=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4=MLPClassifier(hidden_layer_sizes=(100,),batch_size=64,early_stopping=True)\n",
    "model_4.fit(X_tr_tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=model_4.predict(X_te_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(p, columns = ['SECTION']).to_excel('predictions_13.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SECTION\n",
       "0        1\n",
       "1        2\n",
       "2        1\n",
       "3        1\n",
       "4        1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf13=pd.read_excel('predictions_13.xlsx')#it got test accuracy of 0.98108\n",
    "pdf13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6WWJMPf1_pG"
   },
   "outputs": [],
   "source": [
    "# Politics: 0\n",
    "# Technology: 1\n",
    "# Entertainment: 2\n",
    "# Business: 3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of All_ML_codes1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
